{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import torchvision\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import MemeCaptionDataset\n",
    "from captionmodel import EncoderCNN, DecoderRNN\n",
    "from torchgan.models import DCGANGenerator\n",
    "from infer_caption import pred_vec_to_text\n",
    "\n",
    "from settings import caption_batch_size, workers\n",
    "\n",
    "to_pil = torchvision.transforms.ToPILImage(mode='RGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point these to the model checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# GAN_PARAMS_TO_LOAD = 'trained_model.model'\n",
    "GAN_PARAMS_TO_LOAD = 'gan0.model'\n",
    "ENCODER_PARAMS_TO_LOAD = 'encoder-440.pth'\n",
    "DECODER_PARAMS_TO_LOAD = 'decoder-440.pth'\n",
    "\n",
    "GAN_CKPT_PATH = f'./model/{GAN_PARAMS_TO_LOAD}'\n",
    "ENCODER_CKPT_PATH = f'./caption-model-ckpts/{ENCODER_PARAMS_TO_LOAD}'\n",
    "DECODER_CKPT_PATH = f'./caption-model-ckpts/{DECODER_PARAMS_TO_LOAD}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the models for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the meme background generator\n",
    "\n",
    "generator_state_dict = torch.load(\n",
    "    GAN_CKPT_PATH,\n",
    "    map_location=torch.device(device)\n",
    ")['generator']\n",
    "\n",
    "generator = DCGANGenerator(\n",
    "    encoding_dims=100,\n",
    "    out_size=64,\n",
    "    out_channels=3,\n",
    "    step_channels=64,\n",
    "    nonlinearity=nn.LeakyReLU(0.2),\n",
    "    last_nonlinearity=nn.Tanh(),\n",
    ").to(device)\n",
    "\n",
    "generator.load_state_dict(\n",
    "    state_dict=generator_state_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CNN Encoder and RNN Decoder\n",
    "dataset = MemeCaptionDataset()\n",
    "\n",
    "data_loader = iter(torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=caption_batch_size,\n",
    "    shuffle=True, \n",
    "    num_workers=workers\n",
    "))\n",
    "\n",
    "vocab_size = len(dataset.itos)\n",
    "\n",
    "encoder = EncoderCNN().to(device)\n",
    "decoder = DecoderRNN(\n",
    "    embed_size=1024, \n",
    "    hidden_size=1024, \n",
    "    vocab_size=vocab_size\n",
    ").to(device)\n",
    "\n",
    "encoder.load_state_dict(\n",
    "    torch.load(ENCODER_CKPT_PATH, map_location=torch.device(device))\n",
    ")\n",
    "\n",
    "decoder.load_state_dict(\n",
    "    torch.load(DECODER_CKPT_PATH, map_location=torch.device(device))\n",
    ")\n",
    "encoder.eval()\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Some Memes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_full import create_meme\n",
    "\n",
    "memes_to_generate = 10\n",
    "memes = []\n",
    "for _ in range(memes_to_generate):\n",
    "    meme = create_meme(\n",
    "        encoder=encoder,\n",
    "        decoder=decoder,\n",
    "        generator=generator,\n",
    "        data_loader=data_loader,\n",
    "        device=device,\n",
    "        dataset=dataset\n",
    "    )\n",
    "    memes.append(np.array(meme))\n",
    "    \n",
    "stacked_memes_1 = np.concatenate(memes[:memes_to_generate//2], axis=1)\n",
    "stacked_memes_2 = np.concatenate(memes[memes_to_generate//2:], axis=1)\n",
    "memes = np.concatenate([stacked_memes_1, stacked_memes_2], axis=0)\n",
    "plt.axis('off')\n",
    "plt.imshow(np.asarray(memes), interpolation=None)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0bfb55678b138eb60cc9deb78e253b84599eb01fd2c2c1933934246cf45226c8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
